---
title: "Cookie Cats AB Test Analysis"
author: "Alexandra Lugo"
date: "2026-02-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
---

# Executive Summary

# 1. Problem Statement & Hypothesis
**Business Context:**
Cookie Cats is a mobile puzzle game where players encounter "gates" that force them to wait or make in-app purchases to progress. The company tested moving the first gate from level 30 to level 40 to see if this impacts players retention.

**Research Question:**
Does moving the gate from level 30 to level 40 affect 1-day and 7-day player retention?

**Hypotheses:**

- **Null Hypothesis (H₀):** Gate placement has no effect on retention rates
- **Alternative Hypothesis (H₁):** Gate placement significantly affects retention rates

**Success Metrics:**

- **Primary:** 7-day retention rate (retention_7)  
- **Secondary:** 1-day retention rate (retention_1)  
- **Significance Level:** α = 0.05

___

# 2. Setup & Data Loading
```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    fig.width = 10,
    fig.height = 6
)
```
```{r load-libraries}
#load required libraries
library(tidyverse)
library(scales)
library(knitr)
library(broom)
```
```{r load-data}
#import dataset
df <- read_csv("cookie_cats.csv")

#display structure
glimpse(df)
```
___

# 3. Data Quality Checks
```{r data-quality}
#check for missing values
cat("Missing values by column:\n")
colSums(is.na(df))

#summary statistics
summary(df)

#check unique values in version column
cat("\nUnique gate versions:\n")
table(df$version)
```
___

#  4. Exploratory Data Analysis

## Sample Size by Group
```{r sample-size-table}
#Create summary table
sample_summary <- df %>%
  group_by(version) %>%
  summarise(
    n_players = n(),
    pct_of_total = percent(n() / nrow(df), accuracy = 0.1)
  ) %>%
  arrange(desc(n_players))

kable(sample_summary, col.names = c("Gate Version", "Number of Players", "% of Total"), 
      caption = "Sample Size Distribution by Test Group")
```
```{r basic-metrics}
# calculate baseline retention rates
retention_summary <- df %>%
  group_by(version) %>%
  summarise(
    n_players = n(),
    retention_1_rate = mean(retention_1, na.rm = TRUE),
    retention_7_rate = mean(retention_7, na.rm = TRUE),
    avg_game_rounds = mean(sum_gamerounds, na.rm = TRUE)
  )

kable(retention_summary, digits=3, col.names = c("Gate Version", "Players", "Day 1 Retention ", "Day 7 Retention ", "Avg Game Rounds"), 
      caption = "Baseline Metricsby Test Group")
```
___

## Initial Observations

Based on the descriptive statistics:

- **Sample sizes are well-balanced:** 44,700 vs 45,489 players (49.6% vs 50.4%)
- **Day 1 retention:** gate_30 shows 44.8% retention vs gate_40's 44.2% (0.6 percentage point difference)
- **Day 7 retention:** gate_30 shows 19.0% retention vs gate_40's 18.2% (0.8 percentage point difference)
- **Engagement levels:** Both groups played similar average rounds (~51-52 rounds)

**Next step:** Determine if these observed differences are statistically significant or due to random chance.

___

## Viz 1: Retention Rate Comparison with Confidence Intervals
### Confidence Intervals for Retention Rates
```{r ci}
# ===== Calculate confidence intervals for retention rates =====
retention_ci <- df %>%
  group_by(version) %>%
  summarise(
    n = n(),
    #day 1 retention
    retention_1_rate = mean(retention_1),
    retention_1_se = sqrt(retention_1_rate * (1 - retention_1_rate) / n),
    retention_1_ci_lower = retention_1_rate -  1.96 * retention_1_se,
    retention_1_ci_upper = retention_1_rate +  1.96 * retention_1_se,
    # day 7 retention
    retention_7_rate = mean(retention_7),
    retention_7_se = sqrt(retention_7_rate * (1 - retention_7_rate) / n),
    retention_7_ci_lower = retention_7_rate - 1.96 * retention_7_se,
    retention_7_ci_upper = retention_7_rate + 1.96 * retention_7_se
  )

#view results
retention_ci
```

### Plot 1: Day 1 Retention Comparison
```{r day-1-retention-comparison}
# ===== PLOT 1: Day 1 Retention Comparison (FIXED SPACING) =====
ggplot(retention_ci, aes(x = version, y = retention_1_rate, fill = version)) +
  geom_col(alpha = 0.7, width = 0.6) +
  geom_errorbar(aes(ymin = retention_1_ci_lower, ymax = retention_1_ci_upper), 
                width = 0.2, linewidth = 1) +
  geom_text(aes(label = percent(retention_1_rate, accuracy = 0.1)), 
            vjust = -1.5, size = 5, fontface = "bold") +  # Changed vjust from -0.5 to -1.5
  scale_y_continuous(labels = percent_format(), 
                     limits = c(0, 0.52),  # Changed from 0.5 to 0.52
                     breaks = seq(0, 0.5, 0.1)) +
  scale_fill_manual(values = c("gate_30" = "#3498db", "gate_40" = "#e74c3c")) +
  labs(
    title = "Day 1 Retention Rate by Gate Version",
    subtitle = "Error bars show 95% confidence intervals",
    x = "Gate Version",
    y = "Retention Rate",
    caption = "Sample: 90,189 players"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  )
```

### Plot 2: Day 7 Retention Comparison
```{r day-7-retention-comparison}
ggplot(retention_ci, aes(x = version, y = retention_7_rate, fill = version)) +
  geom_col(alpha = 0.7, width = 0.6) +
  geom_errorbar(aes(ymin = retention_7_ci_lower, ymax = retention_7_ci_upper), 
                width = 0.2, linewidth = 1) +
  geom_text(aes(label = percent(retention_7_rate, accuracy = 0.1)), 
            vjust = -2.0, size = 5, fontface = "bold") +  # Changed to -2.0 for more space
  scale_y_continuous(labels = percent_format(), 
                     limits = c(0, 0.23),  # Increased from 0.22 to 0.23
                     breaks = seq(0, 0.25, 0.05)) +
  scale_fill_manual(values = c("gate_30" = "#3498db", "gate_40" = "#e74c3c")) +
  labs(
    title = "Day 7 Retention Rate by Gate Version",
    subtitle = "Error bars show 95% confidence intervals",
    x = "Gate Version",
    y = "Retention Rate",
    caption = "Sample: 90,189 players"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  )
```

___
## Viz 2: Sample Size Sanity Check
### Sample Size Distribution Plot
```{r sample-size-distribution}
# ===== PLOT 3: Sample Size Distribution =====
ggplot(sample_summary, aes(x = version, y = n_players, fill = version)) +
  geom_col(alpha = 0.7, width = 0.6) +
  geom_text(aes(label = comma(n_players)), vjust = -0.5, size = 5, fontface = "bold") +
  scale_y_continuous(labels = comma_format(), limits = c(0, 50000), breaks = seq(0, 50000, 10000)) +
  scale_fill_manual(values = c("gate_30" = "#3498db", "gate_40" = "#e74c3c")) +
  labs(
    title = "Sample Size Distribution: Well-Balanced Test Groups",
    subtitle= "Nearly equal split between control and treatment",
    x = "Gate Version",
    y = "Number of Players",
    caption = "Total: 90,189 players"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  )
```

___

## Visual Interpretation

The bar charts reveal:

1. **Day 1 Retention:** gate_30 (44.8%) slightly outperforms gate_40 (44.2%), but confidence intervals overlap heavily - suggesting the difference may be due to random variation.

2. **Day 7 Retention:** The gap widens at the 7-day mark (19.0% vs 18.2%). This 0.8 percentage point difference is more substantial and warrants statistical investigation.

3. **Sample Balance:** Both groups have ~45,000 players, confirming proper randomization and sufficient statistical power.

**Statistical testing will determine if these observed differences are significant or merely noise.**

___

# 5. Statistical Hypothesis Testing

We'll use **two-proportion z-tests** to determine if the observed differences in retention rates are statistically significant.

**Test Setup:**

- Null Hypothesis (H₀): Retention rates are equal between groups
- Alternative Hypothesis (H₁): Retention rates differ between groups
- Significance level: α = 0.05
- Test: Two-proportion z-test (appropriate for comparing two proportions)

___

## Day 1 Retention Z-Test
```{r day-1-z-test}
# ===== Day 1 Retention Test =====

#prepare data for day 1
gate_30_day1 <- df %>% filter(version == "gate_30") 
gate_40_day1 <- df %>% filter(version == "gate_40")

#count successes (retained players)
n_30_day1 <- nrow(gate_30_day1)
n_40_day1 <- nrow(gate_40_day1)
retained_30_day1 <- sum(gate_30_day1$retention_1)
retained_40_day1 <- sum(gate_40_day1$retention_1)

#perform two-proportion z-test
day1_test <- prop.test(x = c(retained_30_day1, retained_40_day1), 
                          n = c(n_30_day1, n_40_day1), 
                          alternative = "two.sided", 
                          conf.level = 0.95,
                          correct = FALSE)
#display results
day1_test
```

### Extract Key Metrics for Day 1
``` {r extract-key-metrics-day1}
# ===== Extract Key Metrics for Day 1 Test =====

#calculate proportions and effect size
p_30_day1 <- retained_30_day1 / n_30_day1
p_40_day1 <- retained_40_day1 / n_40_day1
effect_size_day1 <- p_30_day1 - p_40_day1

#create results table
day1_results <- data.frame(
  Metric = c("gate_30 Retention Rate", 
  "gate_40 Retention Rate", 
  "Difference (gate_30 - gate_40)",
  "95% CI Lower Bound",
  "95% CI Upper Bound",
  "Z-statistic",
  "P-value",
  "Statistically Significant?"),
  Value = c(percent(p_30_day1, accuracy = 0.01),
            percent(p_40_day1, accuracy = 0.01),
            percent(effect_size_day1, accuracy = 0.01),
            percent(day1_test$conf.int[1], accuracy = 0.01),
            percent(day1_test$conf.int[2], accuracy = 0.01),
            as.character(round(sqrt(day1_test$statistic), 3)),
            format(day1_test$p.value, scientific = TRUE, digits = 3),
            ifelse(day1_test$p.value < 0.05, "Yes (p < 0.05)", "No (p >= 0.05)"))
)

kable(day1_results, caption = "Day 1 Retention Test Results")
```

## Day 7 Retention Z-Test
```{r day-7-z-test}
# ===== Day 7 Retention Test =====

#count successes (retained players at day 7)
retained_30_day7 <- sum(gate_30_day1$retention_7)
retained_40_day7 <- sum(gate_40_day1$retention_7)

#perform two-proportion z-test for day 7
day7_test <- prop.test(x = c(retained_30_day7, retained_40_day7), 
                          n = c(n_30_day1, n_40_day1), 
                          alternative = "two.sided", 
                          conf.level = 0.95,
                          correct = FALSE)
#display results
day7_test
```

### Extract Key Metrics for Day 7
```{r extract-key-metrics-day7}
# ===== Extract Key Metrics for Day 7 Test =====

#calculate proportions and effect size for day 7
p_30_day7 <- retained_30_day7 / n_30_day1
p_40_day7 <- retained_40_day7 / n_40_day1
effect_size_day7 <- p_30_day7 - p_40_day7

#create results table for day 7
day7_results <- data.frame(
  Metric = c("gate_30 Retention Rate", 
  "gate_40 Retention Rate", 
  "Difference (gate_30 - gate_40)",
  "95% CI Lower Bound",
  "95% CI Upper Bound",
  "Z-statistic",
  "P-value",
  "Statistically Significant?"),
  Value = c(percent(p_30_day7, accuracy = 0.01),
            percent(p_40_day7, accuracy = 0.01),
            percent(effect_size_day7, accuracy = 0.01),
            percent(day7_test$conf.int[1], accuracy = 0.01),
            percent(day7_test$conf.int[2], accuracy = 0.01),
            as.character(round(sqrt(day7_test$statistic), 3)),
            format(day7_test$p.value, scientific = TRUE, digits = 3),
            ifelse(day7_test$p.value < 0.05, "Yes (p < 0.05)", "No (p >= 0.05)"))
)

kable(day7_results, caption = "Day 7 Retention Test Results")
```

## Comparison Viz: Confidence Intervals
```{r comparison-viz-ci}
# ===== PLOT 4: Retention Rate Comparison with Confidence Intervals =====

ci_comparison <- data.frame(
  Metric = c("Day 1 Retention", "Day 7 Retention"),
  Difference = c(effect_size_day1, effect_size_day7),
  CI_Lower = c(day1_test$conf.int[1], day7_test$conf.int[1]),
  CI_Upper = c(day1_test$conf.int[2], day7_test$conf.int[2]),
  Significant = c(
    ifelse(day1_test$p.value < 0.05, "Significant", "Not Significant"),
    ifelse(day7_test$p.value < 0.05, "Significant", "Not Significant")
  )
)

ggplot(ci_comparison, aes(x = Metric, y = Difference, fill = Significant)) +
  geom_point(size=4) +
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.2, linewidth = 1.2) +
  geom_hline(yintercept = 0, linetype='dashed', color='gray50', linewidth=1) +
  scale_y_continuous(labels = percent_format(), breaks = seq(-0.01, 0.01, 0.005)) +
  scale_color_manual(values = c("Significant" = "#27ae60", "Not Significant" = "#e74c3c")) +
  labs(
    title = "Effect Size: gate_30 vs gate_40",
    subtitle = "95% Confidence Intervals for Retention Rate Differences",
    x = NULL,
    y = "Difference in Retention Rate\n(gate_30 - gate_40)",
    caption = "Dashed line at 0 = no difference. Intervals excluding 0 = significant effect."
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  )
```

___

## Key Findings

Based on the two-proportion z-tests:

**Day 1 Retention:**

- **Effect size:** `r percent(effect_size_day1, accuracy = 0.01)` (gate_30 retained more players)
- **P-value:** `r format(day1_test$p.value, scientific = FALSE, digits = 3)`
- **Conclusion:** `r ifelse(day1_test$p.value < 0.05, "**Statistically significant** - The difference is unlikely due to chance.", "**Not statistically significant** - The difference could be due to random variation.")`

**Day 7 Retention:**

- **Effect size:** `r percent(effect_size_day7, accuracy = 0.01)` (gate_30 retained more players)
- **P-value:** `r format(day7_test$p.value, scientific = FALSE, digits = 3)`
- **Conclusion:** `r ifelse(day7_test$p.value < 0.05, "**Statistically significant** - The difference is unlikely due to chance.", "**Not statistically significant** - The difference could be due to random variation.")`

**Overall Assessment:**
The 7-day retention metric shows a `r ifelse(day7_test$p.value < day1_test$p.value, "stronger", "weaker")` effect and is the more reliable indicator of long-term player behavior. 

___

## Business Impact Estimation
```{r business-impact-calc}
# ===== Business Impact Calculation =====

#assumptions
total_new_players_per_month <- 1000000  # 1M new players/month (example)
average_revenue_per_retained_player <- 2.50  # $2.50 LTV for 7-day retained players

#calculate impact
retention_loss_pct <- effect_size_day7  # 0.82% fewer players retained
players_lost_per_month <- total_new_players_per_month * retention_loss_pct
revenue_lost_per_month <- players_lost_per_month * average_revenue_per_retained_player
revenue_lost_per_year <- revenue_lost_per_month * 12

#create impact table
business_impact <- data.frame(
  Metric = c(
    "7-Day Retention Loss",
    "Players Lost per Month (1M new players)",
    "Monthly Revenue Impact ($2.50 LTV)",
    "Annual Revenue Impact"
  ),
  Value = c(
    percent(retention_loss_pct, accuracy = 0.01),
    comma(players_lost_per_month),
    dollar(revenue_lost_per_month),
    dollar(revenue_lost_per_year)
  )
)

kable(business_impact, 
      caption = "Estimated Business Impact of Moving Gate to Level 40")
```
___

# 6. Segmentation Analysis

Does the gate placement effect vary by player engagement level? Let's segment players based on their total game rounds played.

___
## Define Player Segments
```{r create-player-segments}
# ===== Create Player Segments =====

df_segmented <- df %>%
  mutate(
    player_segment = case_when(
      sum_gamerounds < 16 ~ "Light Players (<16 rounds)",
      sum_gamerounds >= 16 & sum_gamerounds <= 51 ~ "Medium Players (16-50 rounds)",
      sum_gamerounds > 51 ~ "Heavy Players (51+ rounds)"
    ),
    #create ordered factor for plotting
    player_segment = factor(player_segment, levels = c("Light Players (<16 rounds)", 
                                                      "Medium Players (16-50 rounds)", 
                                                      "Heavy Players (51+ rounds)"))
  )
#check segment distribution
segment_summary <- df_segmented %>%
  group_by(player_segment) %>%
  summarise(n_players = n(),
  pct_of_total = percent(n() / nrow(df_segmented), accuracy = 0.1))

kable(segment_summary, col.names = c("Player Segment", "Number of Players", "% of Total"), 
      caption = "Player Segmentation Distribution")
```

## Retention Rates by Segment and Gate Version
```{r calc-retention-by-segment}
# ===== Calculate Retention Rates by Segment =====

segment_retention <- df_segmented %>%
  group_by(player_segment, version) %>%
  summarise(
    n_players = n(),
    retention_1_rate = mean(retention_1, na.rm = TRUE),
    retention_7_rate = mean(retention_7, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(player_segment, version)

kable(segment_retention, digits=3, col.names = c("Player Segment", "Gate Version", "Players", "Day 1 Retention ", "Day 7 Retention"), 
      caption = "Retention Rates by Player Segment and Gate Version")
```

## Calculate Effect Size by Segment
```{r calc-effect-size-by-segment}
# ===== Calculate Effect Size by Segment =====

segment_effects <- df_segmented %>%
  group_by(player_segment, version) %>%
  summarise(
    retention_7_rate = mean(retention_7, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = version,
    values_from = retention_7_rate
  ) %>%
  mutate(
    effect_size = gate_30 - gate_40,
    effect_size_pct = percent(effect_size, accuracy = 0.01)
  )

kable(segment_effects, 
      digits = 4,
      col.names = c("Player Segment", "gate_30 Retention", 
                    "gate_40 Retention", "Effect Size", "Effect Size %"),
      caption = "Day 7 Retention Effect Size by Player Segment")
```

## Viz: Segmentation Analysis
```{r plot-segmentation-analysis}
# ===== PLOT 5: Day 7 Retention by Player Segment =====

ggplot(segment_retention, aes(x = player_segment, y = retention_7_rate, fill = version)) +
  geom_col(position = 'dodge', alpha = 0.8, width = 0.7) +
  geom_text(aes(label = percent(retention_7_rate, accuracy = 0.1)), 
            position = position_dodge(width = 0.7), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = percent_format(), limits = c(0, 0.6), breaks = seq(0, 0.6, 0.1)) +
  scale_fill_manual(values = c("gate_30" = "#3498db", "gate_40" = "#e74c3c")) +
  labs(
    title = "Day 7 Retention Rate by Player Engagement Segment",
    subtitle = "Gate placement has the strongest negative effect on medium engagement players",
    x = "Player Segment",
    y = "Day 7 Retention Rate",
    fill = "Gate Version",
    caption = "Sample: 90,189 players"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold", size = 15),
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 20, hjust = 1)
  )
```

___

## Key Segmentation Findings

**Player Distribution:**
The three segments show dramatically different retention profiles:

**Effect Size by Segment (7-Day Retention):**

1. **Light Players (< 16 rounds):** 2.4% retention in both groups
   - **Effect:** Virtually zero (2.4% vs 2.4%)
   - **Interpretation:** Casual players churn quickly regardless of gate position. Not sensitive to game design changes.

2. **Medium Players (16-50 rounds):** ~13-14% retention
   - **Effect:** +1.4 percentage points for gate_30 (14.4% vs 13.0%)
   - **Interpretation:** Moderately engaged players show some sensitivity to gate timing.

3. **Heavy Players (51+ rounds):** ~54-57% retention
   - **Effect:** +4.6 percentage points for gate_30 (56.8% vs 54.2%)
   - **Interpretation:** **Most engaged players are MOST sensitive to gate placement.** This is the critical finding.

___

## Business Implication

**The gate effect scales with engagement:**

The more invested a player becomes, the more frustrating the delayed gate feels. This is counterintuitive but reveals important player psychology:

- **Casual players** bounce regardless (2.4% retention = ~98% churn)
- **Core players** (Heavy segment) show 4.6pp retention loss when gate moves to level 40
- **Heavy players represent your highest LTV segment** - they're the ones who stick around, make purchases, and generate revenue

**Critical insight:** Moving the gate to level 40 disproportionately harms your most valuable players. The $246K annual revenue loss estimate may be **understated** because it doesn't fully account for the higher lifetime value of heavy players.

___
### Segmentation Insight Strengthens Recommendation

The segmentation analysis reveals that **heavy players (51+ rounds) experience a 4.6 percentage point retention drop** with gate_40, while casual players show zero effect. This means:

1. **Revenue impact is concentrated:** The loss isn't spread evenly - it hits your highest-value users hardest
2. **LTV multiplier effect:** Heavy players likely have 5-10x higher lifetime value than casual players, amplifying the financial impact
3. **Retention compounds:** Losing 4.6% of engaged players at Day 7 likely cascades into even larger losses at Day 30, Day 90, etc.

**Revised revenue estimate:** If heavy players generate $10+ LTV (vs $2.50 average), the annual impact could exceed **$500,000+** in lost revenue.

___
## Viz: Heatmap
```{r plot-heatmap-effect-size}
# ===== PLOT 6: Heatmap of Effect Size by Segment =====

#prep data for heatmap
heatmap_data <- df_segmented %>%
  group_by(player_segment, version) %>%
  summarise(
    retention_1 = mean(retention_1, na.rm = TRUE),
    retention_7 = mean(retention_7, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(cols = c(retention_1, retention_7),
               names_to = "metric",
               values_to = "retention_rate") %>%
  mutate(
    metric = case_when(
      metric == "retention_1" ~ "Day 1 Retention",
      metric == "retention_7" ~ "Day 7 Retention"
    )
  )

ggplot(heatmap_data, 
       aes(x = version, y = player_segment, fill = retention_rate)) +
  geom_tile(color = "white", linewidth = 1) +
  geom_text(aes(label = percent(retention_rate, accuracy = 0.1)),
            color = "white", fontface = "bold", size = 4) +
  scale_fill_gradient(low = "#e74c3c", high = "#27ae60",
                      labels = percent_format()) +
  facet_wrap(~ metric) +
  labs(
    title = "Retention Heatmap: Gate Version vs Player Engagement",
    subtitle = "Darker green = higher retention. Pattern shows gate_30 consistently outperforms gate_40.",
    x = "Gate Version",
    y = "Player Engagement Segment",
    fill = "Retention\nRate"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 15),
    strip.text = element_text(face = "bold", size = 12),
    axis.text.x = element_text(angle = 0),
    panel.grid = element_blank()
  )
```
